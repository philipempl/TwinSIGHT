version: '3'
services:

#---------------------------------------- Zookeeper ----------------------------------------------------

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      default:
        aliases:
          - zookeeper

#---------------------------------------- MQTT Broker  --------------------------------------------------

  hivemq:
    image: hivemq/hivemq-ce
    hostname: hivemq
    container_name: hivemq
    restart: always
    ports:
      - "1883:1883"
      - "8883:8883"
      - "18083:18083"
    networks:
      default:
        aliases:
          - hivemq

#---------------------------------------- Ditto (Digital Twin) -------------------------------------------

  mongodb:
    image: docker.io/mongo:${MONGO_VERSION}
    networks:
      default:
        aliases:
          - mongodb
    command: mongod --storageEngine wiredTiger --noscripting
    user: mongodb
    ports:
      - 27017:27017
    environment:
       TZ: Europe/Berlin

  policies:
    image: docker.io/eclipse/ditto-policies:${DITTO_VERSION}
    mem_limit: 512m
    networks:
      default:
        aliases:
          - ditto-cluster
    environment:
      - TZ=Europe/Berlin
      - INSTANCE_INDEX=1
      - BIND_HOSTNAME=0.0.0.0
      - OPENJ9_JAVA_OPTIONS=-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -Dakka.coordinated-shutdown.exit-jvm=on -Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      - DITTO_LOGGING_FILE_APPENDER=true
    # Set additional configuration options here
    # -Dditto.policies...
    command: java -jar starter.jar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    volumes:
      - ./volumes/ditto/logs:/var/log/ditto

  things:
    image: docker.io/eclipse/ditto-things:${DITTO_VERSION}
    mem_limit: 512m
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    environment:
      - TZ=Europe/Berlin
      - INSTANCE_INDEX=1
      - BIND_HOSTNAME=0.0.0.0
      - OPENJ9_JAVA_OPTIONS=-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -Dakka.coordinated-shutdown.exit-jvm=on -Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      - DITTO_LOGGING_FILE_APPENDER=true
    # Set additional configuration options here
    # -Dditto.things...
    command: java -jar starter.jar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    volumes:
      - ./volumes/ditto/logs:/var/log/ditto

  things-search:
    image: docker.io/eclipse/ditto-things-search:${DITTO_VERSION}
    mem_limit: 512m
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    environment:
      - TZ=Europe/Berlin
      - INSTANCE_INDEX=1
      - BIND_HOSTNAME=0.0.0.0
      - OPENJ9_JAVA_OPTIONS=-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -Dakka.coordinated-shutdown.exit-jvm=on -Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      - DITTO_LOGGING_FILE_APPENDER=true
    # Set additional configuration options here
    # -Dditto.things-search...
    command: java -jar starter.jar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    volumes:
      - ./volumes/ditto/logs:/var/log/ditto

  concierge:
    image: docker.io/eclipse/ditto-concierge:${DITTO_VERSION}
    mem_limit: 512m
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    environment:
      - TZ=Europe/Berlin
      - INSTANCE_INDEX=1
      - BIND_HOSTNAME=0.0.0.0
      - OPENJ9_JAVA_OPTIONS=-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -Dakka.coordinated-shutdown.exit-jvm=on -Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      - DITTO_LOGGING_FILE_APPENDER=true
    # Set additional configuration options here
    # -Dditto.concierge...
    command: java -jar starter.jar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    volumes:
      - ./volumes/ditto/logs:/var/log/ditto

  connectivity:
    image: docker.io/eclipse/ditto-connectivity:${DITTO_VERSION}
    mem_limit: 768m
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
      - concierge
    environment:
      - TZ=Europe/Berlin
      - INSTANCE_INDEX=1
      - BIND_HOSTNAME=0.0.0.0
      - OPENJ9_JAVA_OPTIONS=-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -Dakka.coordinated-shutdown.exit-jvm=on -Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      - DITTO_LOGGING_FILE_APPENDER=true
    # Set additional configuration options here
    # -Dditto.connectivity...
    command: java -jar starter.jar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    volumes:
      - ./volumes/ditto/logs:/var/log/ditto

  gateway:
    image: docker.io/eclipse/ditto-gateway:${DITTO_VERSION}
    mem_limit: 512m
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
      - concierge
    ports:
      - "8081:8080"
    environment:
      - TZ=Europe/Berlin
      - INSTANCE_INDEX=1
      - BIND_HOSTNAME=0.0.0.0
      - ENABLE_PRE_AUTHENTICATION=true
      - OPENJ9_JAVA_OPTIONS=-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -Dakka.coordinated-shutdown.exit-jvm=on -Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      - DITTO_LOGGING_FILE_APPENDER=true
      # You may use the environment for setting the devops password
      #- DEVOPS_PASSWORD=foobar
    # Set additional configuration options here
    # -Dditto.gateway...
    # Setting the devops password via java VM environment
    command: java -Dditto.gateway.authentication.devops.password=foobar -jar starter.jar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    volumes:
      - ./volumes/ditto/logs:/var/log/ditto

  swagger-ui:
    image: docker.io/swaggerapi/swagger-ui:${SWAGGER_UI_VERSION}
    volumes:
       - ./volumes/ditto/resources/openapi:/usr/share/nginx/html/openapi:ro
       - ./volumes/ditto/resources/images:/usr/share/nginx/html/images:ro
       - ./volumes/ditto/swagger3-index.html:/usr/share/nginx/html/index.html:ro
    command: nginx -g 'daemon off;'

  nginx:
    image: docker.io/nginx:1.20-alpine
    volumes:
       - ./volumes/ditto/nginx.conf:/etc/nginx/nginx.conf:ro
       - ./volumes/ditto/nginx.htpasswd:/etc/nginx/nginx.htpasswd:ro
       - ./volumes/ditto/nginx-cors.conf:/etc/nginx/nginx-cors.conf:ro
       - ./volumes/ditto/index.html:/etc/nginx/html/index.html:ro
       - ./volumes/ditto/resources/images:/etc/nginx/html/images:ro
    ports:
      - "${DITTO_EXTERNAL_PORT:-8080}:80"
    depends_on:
      - gateway
      - swagger-ui

#---------------------------------------- Kafka -----------------------------------------------------

  kafka1:
    image: wurstmeister/kafka:${KAFKA_VERSION}
    command: [start-kafka.sh]
    restart: always
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9091:9091"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka1:19091,OUTSIDE://localhost:9091
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka1:19091,OUTSIDE://localhost:9091
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      default:
        aliases:
          - kafka1
    volumes:
      - ./volumes/kafka1/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"

  kafka2:
    image: wurstmeister/kafka:${KAFKA_VERSION}
    command: [start-kafka.sh]
    restart: always
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9092:9092"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka2:19092,OUTSIDE://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka2:19092,OUTSIDE://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      default:
        aliases:
          - kafka2
    volumes:
      - ./volumes/kafka2/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"

  kafka3:
    image: wurstmeister/kafka:${KAFKA_VERSION}
    command: [start-kafka.sh]
    restart: always
    hostname: kafka3
    container_name: kafka3
    ports:
      - "9093:9093"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka3:19093,OUTSIDE://localhost:9093
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka3:19093,OUTSIDE://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      default:
        aliases:
          - kafka3
    volumes:
      - ./volumes/kafka3/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"

  kafka-ui:
    image: provectuslabs/kafka-ui:${KAFKA_UI_VERSION}
    container_name: kafka-ui
    ports:
      - "9000:8080"
    restart: always
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:19091
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      default:
        aliases:
          - kafka-ui
    depends_on:
      - kafka1
      - kafka2
      - kafka3

#---------------------------------------- ELK Stack ----------------------------------------------------

  elasticsearch:
    hostname: elasticsearch
    container_name: elasticsearch
    build:
      context: volumes/elasticsearch/
    volumes:
      - type: bind
        source: ./volumes/elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx512m -Xms512m"
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      default:
        aliases:
          - elasticsearch

  logstash:
    hostname: logstash
    container_name: logstash
    build:
      context: volumes/logstash/
    volumes:
      - type: bind
        source: ./volumes/logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./volumes/logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    ports:
      - "5044:5044"
      - "5000/tcp"
      - "5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"
    networks:
      default:
        aliases:
          - logstash
    depends_on:
      - elasticsearch
      - kafka1
      - kafka2
      - kafka3

  kibana:
    hostname: kibana
    container_name: kibana
    build:
      context: volumes/kibana/
    volumes:
      - type: bind
        source: ./volumes/kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
      - type: bind
        source: ./volumes/kibana/config/wazuh.yml
        target: /usr/share/kibana/data/wazuh/config/wazuh.yml
    ports:
      - "5601:5601"
    networks:
      default:
        aliases:
          - kibana
    depends_on:
      - elasticsearch
      - wazuh

#---------------------------------------- Wazuh ---------------------------------------------------------------

  wazuh:
    image: wazuh/wazuh-odfe:${WAZUH_VERSION}
    hostname: wazuh
    container_name: wazuh
    restart: always
    ports:
      - "1514:1514"
      - "1515:1515"
      - "514:514/udp"
      - "55000:55000"
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      FILEBEAT_SSL_VERIFICATION_MODE: none
      API_USERNAME: ${WAZUH_API_USERNAME}                            # Wazuh API username
      API_PASSWORD: ${WAZUH_API_PASSWORD}
    volumes:
      - ossec_api_configuration:/var/ossec/api/configuration
      - ossec_etc:/var/ossec/etc
      - ossec_logs:/var/ossec/logs
      - ossec_queue:/var/ossec/queue
      - ossec_var_multigroups:/var/ossec/var/multigroups
      - ossec_integrations:/var/ossec/integrations
      - ossec_active_response:/var/ossec/active-response/bin
      - ossec_agentless:/var/ossec/agentless
      - ossec_wodles:/var/ossec/wodles
      - filebeat_etc:/etc/filebeat
      - filebeat_var:/var/lib/filebeat
    depends_on:
      - elasticsearch
    networks:
      default:
        aliases:
          - wazuh
#---------------------------------------- Volumes and Networks ------------------------------------------------

volumes:
  elasticsearch:
  ossec_api_configuration:
  ossec_etc:
  ossec_logs:
  ossec_queue:
  ossec_var_multigroups:
  ossec_integrations:
  ossec_active_response:
  ossec_agentless:
  ossec_wodles:
  filebeat_etc:
  filebeat_var:
  ditto_log_files:
    driver: local
    driver_opts:
      type: none
      device: /var/log/ditto
      o: bind,uid=1000,gid=1000
